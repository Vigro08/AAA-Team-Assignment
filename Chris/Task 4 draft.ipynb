{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartChargeEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Gym environment for smart charging of electric vehicle.\n",
    "    The taxi arrives home at 14:00 (step 0) and leaves at 16:00 (step 8).\n",
    "    At each 15-minute interval, the agent chooses a charging power level.\n",
    "    The goal is to minimize charging cost and avoid running out of energy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 E_max=50.0,            # Maximum battery capacity in kWh\n",
    "                 p_max=22.0,            # Maximum charging power in kW\n",
    "                 num_bins=23,           # Discrete power levels (including zero)\n",
    "                 mu=30.0, sigma=5.0,    # Demand distribution parameters (kWh)\n",
    "                 fail_penalty=1000.0,   # Penalty if energy < demand at departure\n",
    "                 alpha=None            # Time-based cost coefficients\n",
    "                ):\n",
    "        super(SmartChargeEnv, self).__init__()\n",
    "        \n",
    "        # 1) Environment parameters\n",
    "        self.E_max = E_max\n",
    "        self.p_max = p_max\n",
    "        self.num_steps = int((16 - 14) * 4)  # 8 time steps of 15 minutes\n",
    "        self.dt = 0.25  # 15 minutes = 0.25 hours\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.fail_penalty = fail_penalty\n",
    "        \n",
    "        # Default time-varying cost coefficients if not provided\n",
    "        if alpha is None:\n",
    "            # e.g., higher costs during peak hours (14:00-15:00) vs off-peak\n",
    "            self.alpha = np.linspace(0.1, 0.4, self.num_steps)\n",
    "        else:\n",
    "            assert len(alpha) == self.num_steps\n",
    "            self.alpha = np.array(alpha)\n",
    "\n",
    "        # 2) Action space: discrete power levels from 0 to p_max\n",
    "        self.num_bins = num_bins\n",
    "        self.action_space = spaces.Discrete(self.num_bins)\n",
    "        # Map integer action -> actual power\n",
    "        self.power_levels = np.linspace(0, self.p_max, self.num_bins)\n",
    "\n",
    "        # 3) Observation space: [time_step, energy]\n",
    "        low = np.array([0.0, 0.0], dtype=np.float32)\n",
    "        high = np.array([self.num_steps - 1, self.E_max], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "        # 4) Initialize state\n",
    "        self.state = None  # will hold [time_step, energy]\n",
    "        self.done = False\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to initial state:\n",
    "          - time_step = 0 (14:00)\n",
    "          - energy = current charge (assume starting at 0 or user-defined)\n",
    "        \"\"\"\n",
    "        # For simplicity, we start with an empty battery each day\n",
    "        t0 = 0\n",
    "        E0 = 0.0\n",
    "        self.state = np.array([t0, E0], dtype=np.float32)\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute one time step in the environment:\n",
    "        1) Map action index to charging power\n",
    "        2) Update energy with charging, respecting E_max\n",
    "        3) Compute cost = -exp(alpha[t]) * power\n",
    "        4) If final step, sample demand and apply penalty if needed\n",
    "        5) Increment time, check done flag\n",
    "        \"\"\"\n",
    "        t, E = self.state\n",
    "        t = int(t)\n",
    "\n",
    "        # 1) Get charging power from action index\n",
    "        p = float(self.power_levels[action])\n",
    "\n",
    "        # 2) Update energy\n",
    "        E_next = min(E + p * self.dt, self.E_max)\n",
    "\n",
    "        # 3) Charging cost (negative reward)\n",
    "        cost = -np.exp(self.alpha[t]) * p\n",
    "\n",
    "        reward = cost\n",
    "\n",
    "        # 4) Check terminal condition at final time step\n",
    "        if t == self.num_steps - 1:\n",
    "            # Sample stochastic demand at departure\n",
    "            demand = np.random.normal(self.mu, self.sigma)\n",
    "            # Apply high penalty if battery < demand\n",
    "            if E_next < demand:\n",
    "                reward -= self.fail_penalty\n",
    "            self.done = True\n",
    "        \n",
    "        # 5) Advance time\n",
    "        t_next = t + 1 if not self.done else t\n",
    "        self.state = np.array([t_next, E_next], dtype=np.float32)\n",
    "\n",
    "        info = {\"energy\": E_next}\n",
    "        return self.state, reward, self.done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        t, E = self.state\n",
    "        print(f\"Time Step: {int(t)}/{self.num_steps}, Energy: {E:.2f} kWh\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Quick sanity check\n",
    "    env = SmartChargeEnv()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    while not done:\n",
    "        action = env.action_space.sample()  # random policy\n",
    "        obs, r, done, info = env.step(action)\n",
    "        total_reward += r\n",
    "        env.render()\n",
    "    print(\"Total Reward:\", total_reward)  # should be negative or penalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
